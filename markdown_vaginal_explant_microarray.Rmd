---
output:
  md_document:
    variant: markdown_github
---

"Vaginal explant herpes infection experiment"

```{r,echo=FALSE,message=FALSE, warning=FALSE, results = 'hide'}


###READ IN RAW MICROARRAY DATA FINAL REPORT #######
#data from shared resources

library(plyr)
require(dplyr)
require(lumi)
require(limma)
library(pander)
library(stringr)
library(ggplot2)

#READ IN RAW MICROARRAY DATA FINAL REPORT #######
#data from shared resources

RAW<-"J:\\MacLabUsers\\HLADIK SHARED\\Projects\\Herpes study\\Herpes-Project-1\\vaginal_explant_Illumina\\2015_11_10\\GenomeStudioProject\\SeanHughes_HumanHT12v4_151112\\2015.11.12smhughesFinalReport.txt"

RAW.lumi<-lumiR(RAW,detectionTh = 0.05, na.rm = TRUE,convertNuID = FALSE, dec = '.',
                parseColumnName = FALSE, checkDupId = FALSE,
                QC = TRUE,
                columnNameGrepPattern = list(exprs='AVG_SIGNAL',
                                                       se.exprs='BEAD_STDERR',
                                                       detection='Detection Pval',
                                                       beadNum='Avg_NBEADS'),
                inputAnnotation=TRUE,
                annotationColumn=c('ILMN_GENE', 'ENTREZ_GENE_ID', 'GI', 'ACCESSION', 'SYMBOL', 'PROBE_ID', 'PROBE_START', 'PROBE_SEQUENCE', 'CHROMOSOME', 'PROBE_CHR_ORIENTATION', 'PROBE_COORDINATES'),
                verbose = TRUE)


save(RAW.lumi, file="RAW.lumi.Rdata")
```

EXPERIMENT NOTES

6 samples failed when the microarray was run (6, 33, 34, 35, 45, 63)
and two failed QC (36,64).


FAILED SAMPLES
6 One of the T-cell samples, not included in the explant study

33 ID326 3hr MOCK

34 ID 326 8hr SD90

35 ID 326 24hr V186

36 ID 317 8hr MOCK

45 ID 318 24hr SD90

63 ID 327 8hr SD90

64 ID 319 8hr MOCK


Samples that failed the finalReport file were not included in the report we got from shared resources and I removed the ones that failed QC.

ALSO

The first 6 samples in the micrarray data are T cells that 
were exposed to Tenofovir. These will be analyzed separately so I removed them from the data set here.


```{r,echo=FALSE,message=FALSE, warning=FALSE}
########### SUBSETTING THE LUMIBATCH 

#subset the lumibatch to remove the non-explant data AND the two samples
#that were left in the finalReport but failed the QC
RAW.lumi<-RAW.lumi[,-c(1:5,32,58)]#32 and 58 are the indices for
#samples "36" and "64"

#read in phenoData (does NOT include any phenoData for non-explant samples)

pData<- read.table("explantMicroarrayPhenoData.txt",
                       sep="\t",row.names=1, header=TRUE)




#make the rownames character(they are numbers, but are actually
#sample names and lumi has them as character)

rownames(pData)<-as.character(rownames(pData))
pData$TissueID<-as.character(pData$TissueID)
pData$Time <- as.character(pData$Time)


#need to remove phenodata for the samples that failed. The rownames
#start at 7 (1-6 were the tenofovir samples). So the sampleNames are now
#6 ahead of the the row numbers (sample 33 is in the 27th row of data)
# missing samples 33=ID326 T1 M D1
#34=ID 326 T2 V1 D1
#35=ID 326 T3 V2 D1
#36 ID 317 T2 M D1
#45 ID 318 T3 V1 D1
#63 ID 327 T2 V1 D1
#64 ID 319 T2 M D1

#make a vector of rownames I want to remove
toExclude<-c("33","34","35","36","45","63","64")

#to get the indices of the rownames that I want to remove:
#>which(rownames(pData)%in% toExclude)

#and then remove those indices from pData

pData<-pData[-which(rownames(pData)%in% toExclude),]



#create metadata df
metadata<- data.frame(labelDescription = c("Tissue,Time,Virus",
                                           "PTID","Sampling Time","Virus: V1=strain SD90, V2=strain 186, M=Mock", "Treatment:either a virus strain or Mock.",
                                           "Location of original RNA on 96well plate"),
                      row.names=c("DescriptiveSampleID","TissueID","Time","Dose","Treatment","PlateID"))


#combine metadata and pdata into an annotated df
adf<-new("AnnotatedDataFrame",data=pData,varMetadata=metadata)

#create experiment data
experimentData<-new("MIAME",name="Claire Levy",
                    lab="Florian Hladik Lab",title="Vaginal Explant Microarray")


#make a lumiBatch that contains both the raw data we got from
#shared resources AND the phenoData, metadata and experiment data
#that I created MINUS the tenofovir data and the failed samples.

complete.RAW.lumi<-new("LumiBatch", exprs=exprs(RAW.lumi),phenoData=adf,
                  experimentData=experimentData,
                  se.exprs=se.exprs(RAW.lumi),
                  detection=detection(RAW.lumi),
                  featureData=featureData(RAW.lumi))

save(complete.RAW.lumi,file="complete.RAW.lumi.Rdata")
```

 SOME PLOTS OF NON NORMALIZED DATA:
 density plot, cdf plot, sample relations
 
```{r,echo=FALSE,message=FALSE, warning=FALSE}
#density plot
density(complete.RAW.lumi)#number of probes for each sample that occur
#at a certain log2 intensity

#CDF plot: cumulative probability of having <= a certain log2 intensity
plotCDF(complete.RAW.lumi)

#sample relations
plot(complete.RAW.lumi, what='sampleRelation',method="mds")

#boxplot
boxplot(complete.RAW.lumi)

```


```{r,echo=FALSE,message=FALSE, warning=FALSE, results = 'hide'}
######## BACKGROUND CORRECTION 
#the data we got from the core had no background correction so I will do it here

B.complete.RAW.lumi<-lumiB(complete.RAW.lumi)


#################### VST TRANSFORMATION 
#"Stabilizing the expression variance based on
#the bead level expression variance and mean relations"

TB.complete.RAW.lumi <-lumiT (B.complete.RAW.lumi)

################## ROBUST SPLINE NORMALIZATION 

NTB.complete.RAW.lumi<-lumiN(TB.complete.RAW.lumi,method="rsn")

################# QUALITY CONTROL 

QNTB.complete.RAW.lumi <- lumiQ(NTB.complete.RAW.lumi,detectionTh=0.05)

save(QNTB.complete.RAW.lumi, file = "QNTB.complete.RAW.lumi.Rdata")
```

PLOTS OF NORMALIZED DATA 

```{r,echo=FALSE,message=FALSE, warning=FALSE}
plot(QNTB.complete.RAW.lumi)


plot(QNTB.complete.RAW.lumi, what='sampleRelation',method="mds")

boxplot(QNTB.complete.RAW.lumi)


#trying to find which sample makes the outlier bump
#exp<-as.data.frame(exprs(QNTB.complete.RAW.lumi))

# exp$Probes<-rownames(exp)
# 
# rownames(exp)<- NULL
# 
# melt<-melt(exp, id.vars="Probes")
# 
# sum<-melt%>%
#   group_by(variable)%>%
#   summarize(count=sum(value>7.1))%>%
#   arrange(desc(count))
  
#plot(QNTB.complete.RAW.lumi[,"32"])





```


FILTERING PROBES 
 Limma suggests to keep probes that are expressed above background on 
at least n arrays where n is smallest number of replicates assigned
to any of the treatment combinations.

Our treatment combinations are TissueID/Treatment/Time.
We  have 7 replicates (donors) for each of the treatment combinations so I kept probes with detection levels above background in at least 7 samples.

```{r,echo=FALSE,message=FALSE, warning=FALSE}
#this is how the detection filtering works:
#Mark the detection pvalues (there is one per probe per sample) with a 1 if <0.05 or a 0 if >0.05
# using (detection(QNTB.complete.RAW.lumi)<0.05)

#add up the 0's and 1's across each row (i.e. for all the samples)
#using rowSums

#now you have the number of detection p values <0.05 for each probe
#for all the samples (max possible = total samples)

#now tell me which probes have a rowSum of >=7 (probes will be marked as TRUE
# or false if they do or do not have >=7 rowSum)
            
detectedProbes <- rowSums(detection(QNTB.complete.RAW.lumi)<0.05)>=7

#now extract just those probes that are TRUE from the lumibatch

expressedProbes.lumi <-QNTB.complete.RAW.lumi[detectedProbes,]


#after filtering, mds plot is basically the same as before
#plot(expressedProbes.lumi, what='sampleRelation',method="mds")


```

Number of probes in data set before filtering:

```{r,echo=FALSE,message=FALSE, warning=FALSE}
dims(QNTB.complete.RAW.lumi)[1]#47323
```

Number of probes in data set after filtering:

```{r,echo=FALSE,message=FALSE, warning=FALSE}

dims(expressedProbes.lumi)[1]

```

Number of probes removed by filtering:

```{r,echo=FALSE,message=FALSE, warning=FALSE}
dims(QNTB.complete.RAW.lumi)[1]-dims(expressedProbes.lumi)[1]

save(expressedProbes.lumi, file="expressedProbes.lumi.Rdata")
```

The design matrix includes a combined treatment + timepoint parameter (`r "Treat" `) and a donor parameter (`r "TissueID" `).

`r design <-(~0+Treat+TissueID)`


```{r,echo=FALSE,message=FALSE, warning=FALSE}

############### TARGETS AND DESIGN MATRIX 
# see section 9.4.1 and 9.4.2 in the limma users guide

targets<-pData(expressedProbes.lumi)%>%
  select(TissueID, Treatment,Time)
TissueID<- factor(targets$TissueID)
Treat <-factor(paste(targets$Treatment,targets$Time, sep="."))

design<-model.matrix (~0+Treat+TissueID)

```

Then we choose the comparisons we want to analyze. I compared each treatment + timepoint condition with the corresponding mock infection in the same donor. This gives 6 contrasts to analyze:

  V186.3vsMock.3
  
  V186.8vsMock.8
  
  V186.24vsMock.24 
  
  SD90.3vsMock.3 
  
  SD90.8vsMock.8 
  
  SD90.24vsMock.24


```{r,echo=FALSE,message=FALSE, warning=FALSE}

####################### FIT MODEL TO PROBES

fit <- lmFit(expressedProbes.lumi,design=design)
save(fit, file="fit.Rdata")

#Now we can make any comparisons
#between the experimental conditions

# If topTable is called and coef has two or more elements,
# then the specified columns will be extracted from fit and
# topTableF called on the result. topTable with coef=NULL is 
# the same as topTableF, unless the fitted model fit has only
# one column.

bothcm<-makeContrasts(
  V186.3vsMock.3 = TreatV186.3-TreatMock.3,
  V186.8vsMock.8 = TreatV186.3-TreatMock.8,
  V186.24vsMock.24 = TreatV186.24-TreatMock.24,
  SD90.3vsMock.3 = TreatSD90.3-TreatMock.3,
  SD90.8vsMock.8 = TreatSD90.8-TreatMock.8,
  SD90.24vsMock.24 = TreatSD90.24-TreatMock.24,
  levels=design
)


#fit the contrasts  
fit2<-contrasts.fit(bothcm, fit=fit)


#compute diff exprsn
fit2 <-eBayes(fit2)

save(fit2, file= "fit2eBayes.Rdata")
```

After fitting the contrasts to the model using our design matrix, we can see how many probes are up and down-regulated for each contrast, based on a p-value cut-off of 0.05 and a log-fold-change cut-off of 0.5.


```{r,echo=FALSE,message=FALSE, warning=FALSE}

#method=separate is same as doing topTable for all coefs separately

results <- decideTests(fit2,method="separate", adjust.method="BH",
                      p.value=0.05, lfc=0.5)

save(results, file= "decideTestsResults.Rdata")

#turn the results matrix into a data frame and make the
#probeID a real column and remove the rownames

resultsDF<-as.data.frame(results)
resultsDF$ProbeID<-rownames(resultsDF)
rownames(resultsDF)<-NULL

#melt the df for easy summarizing
library(reshape2)

resultsDFmelt<-melt(resultsDF, id.vars="ProbeID")
save(resultsDFmelt,file = "resultsDFmelt.Rdata")
#number of up and down regulated probes based on 
#p.val at most 0.05 and lfc at least 0.5

summary<-resultsDFmelt %>%
  group_by(variable)%>%
 summarize(down=sum(value=="-1"),up=sum(value=="1"))

library(pander)
pander(summary)

save(summary, file = "summary.Rdata")

```


V186 vs mock at 3hr


```{r,echo=FALSE,message=FALSE, warning=FALSE}
############### TOP TABLE AND HEAT MAPS #############

#adj p values <0.05 and lfc >=0.5
#get the toptable for this contrast
tt1<-topTable(fit2,coef="V186.3vsMock.3", adjust.method = "BH", number=Inf, p.value=0.05, lfc=0.5)


#get the probes that are in the top table
selected1<-rownames(tt1) #selecting the probes of interest

#from the expressedProbes.lumi batch, select just the samples #corresponding to the corresponding coefs (time=24, treatment not SD90)

esetSel1<-expressedProbes.lumi[selected1,targets$Time=="3"& targets$Treatment !="SD90" ]

#To have informative names along the bottom of the heatmap,replace #the true Sample Names(numbers)with their corresponding treatment.
#i.e. look at the rows in expressedProbes.lumi that match the colnames in exprs and provide the value for Treatment in those rows. Set that as the new colnames.

colnames(exprs(esetSel1))<-pData(expressedProbes.lumi)[colnames(esetSel1),"Treatment"]

heatmap(exprs(esetSel1))

```

V186 vs mock at 8hr

```{r,echo=FALSE,message=FALSE, warning=FALSE}
#repeat for coefs 2
tt2<-topTable(fit2,coef="V186.8vsMock.8", adjust.method = "BH", number=Inf, p.value=0.05, lfc=0.5)

selected2<-rownames(tt2) #selecting the probes of interest

esetSel2<-expressedProbes.lumi[selected2,targets$Time=="8"& targets$Treatment !="SD90" ]

colnames(exprs(esetSel2))<-pData(expressedProbes.lumi)[colnames(esetSel2),"Treatment"]


heatmap(exprs(esetSel2))
```

V186 vs mock at 24hr

```{r,echo=FALSE,message=FALSE, warning=FALSE}

#and coef3
tt3<-topTable(fit2,coef="V186.24vsMock.24", adjust.method = "BH", number=Inf, p.value=0.05, lfc=0.5)

selected3<-rownames(tt3) #selecting the probes of interest

esetSel3<-expressedProbes.lumi[selected3,targets$Time=="24"& targets$Treatment !="SD90" ]

colnames(exprs(esetSel3))<-pData(expressedProbes.lumi)[colnames(esetSel3),"Treatment"]

heatmap(exprs(esetSel3))
```

SD90vsMock at 3hr

```{r,echo=FALSE,message=FALSE, warning=FALSE}
#and coef4
tt4<-topTable(fit2,coef="SD90.3vsMock.3", adjust.method = "BH", number=Inf, p.value=0.05, lfc=0.5)

selected4<-rownames(tt4) #selecting the probes of interest

esetSel4<-expressedProbes.lumi[selected4,targets$Time=="3"& targets$Treatment !="V186" ]

colnames(exprs(esetSel4))<-pData(expressedProbes.lumi)[colnames(esetSel4),"Treatment"]

heatmap(exprs(esetSel4))

```

Heat map of V186 AND SD90 at 24hr for probes that were sig for V186.24

```{r,echo=FALSE,message=FALSE, warning=FALSE}


esetSel<-expressedProbes.lumi[selected3, targets$Time=="24"]

colnames(exprs(esetSel))<-pData(expressedProbes.lumi)[colnames(esetSel),"Treatment"]

heatmap(exprs(esetSel))

```

Next I used InnateDB to do GO and Pathway overrepresentation analyses for the V186.24 vs Mock condition for up and down regulated probes and for the V186.3 condition. I didn't get any hits for the pathway analysis for V186.3UP.

Below are the top 10 results. I used the Benjamini-Hochberg p-value correction.

```{r,echo=FALSE,message=FALSE, warning=FALSE}

### PREPARING DATA FOR INNATE DB


#extracting ProbeIDs, symbols and Entrez from fData
ProbeIDandSymbol<-fData(RAW.lumi)[,c(1,4,7)]


#innate db pathway analysis requires probes ids, log fold changes and expression pvalues. 

#I will extract those for V186.24vsMock.24 
#the toptable that I made above ( tt3)


########## V186.24

V186.24ForIDB<-tt3%>%
  select(logFC,adj.P.Val)
 
V186.24ForIDB$ProbeID<-rownames(V186.24ForIDB)

rownames(V186.24ForIDB$ProbeID)<-NULL

V186.24ForIDB<-merge(ProbeIDandSymbol,V186.24ForIDB, by = "ProbeID")

V186.24ForIDBUP<-V186.24ForIDB%>%
  select(ENTREZ_GENE_ID,logFC,adj.P.Val)%>%
  filter(logFC>0)

write.table(V186.24ForIDBUP, file="V186.24ForIDBUP.txt",
            sep="\t", row.names = FALSE)



V186.24ForIDBDOWN<-V186.24ForIDB%>%
  select(ENTREZ_GENE_ID,logFC,adj.P.Val)%>%
  filter(logFC<0)

write.table(V186.24ForIDBDOWN, file="V186.24ForIDBDOWN.txt",
            sep="\t", row.names = FALSE)

##I put the above files into innateDB with the "subset of genes", "hypergeometric" and "Benjamini-Hochberg" options for the pathway ORA. I don't think it matters if pvals are included

### READING IN  ORA DATA FROM INNATE DB

folder <- "J:/MacLabUsers/HLADIK SHARED/Projects/Herpes study/Herpes-Project-1/INNATE DB RESULTS/oraSpreadsheets"

files <- list.files(folder)

filesPath<-paste(folder, "/",files, sep="")

IDBdata <- lapply(filesPath, read.delim, sep="\t", header=TRUE)


#Got no hits in IDB fo v186.3UP pathway ORA

## I got the "number of items read is not a multiple of the number of columns" error for the pathwayV186.24DOWN when I tried to read in with read.table. Don't know why read.delim works. thx stkovrflw

names(IDBdata)<-str_replace(files,pattern=".txt",replacement="")

#For now just look at the top ten pathways


## BIG NOTE #########################################

#when you download the files from the GO ORA from innate DB, the column names are PATHWAY name, PATHWAY Id, PATHWAY pval etc. This is different from what is shown on the actual online interface. see screenshots here: "J:/MacLabUsers/HLADIK SHARED/Projects/Herpes study/Herpes-Project-1/INNATE DB RESULTS

#Bottom line: You can't tell the differences between p-way and GO ORA's based on the downloaded txt file unless you keep the weird long file name that they give. I can use pathway...to refer to columns from both types of df.

###### END BIG NOTE ##################################

### SELECTING COLUMNS OF INTEREST AND CORRECTING COLUMN NAMES ###
makeShort <- function (df){
  df%>%
  arrange(Pathway.p.value..corrected.)%>%
  select(Pathway.Name, Pathway.p.value..corrected.,Source.Name)
}

shortIDBdata<-lapply(IDBdata,FUN=makeShort)

#split into two different lists, one for p-way and one for GO

GOIDBdata<-shortIDBdata[1:4]

names(GOIDBdata)<-names(IDBdata)[1:4]


#filter for just the biological processes and get the top 10 hits
GOfilterSlice<-function(df){
  df%>%filter(Source.Name =="biological process")%>%
  slice(1:10)
}

GOIDBdata<-lapply(GOIDBdata, FUN= GOfilterSlice)

#Here is a function to change the column names to things that make more sense:One for the GO ORA dfs


GOChangeNames<-function(df){
  names(df)<-c("GO Term","Corrected P Value","Source.Name")
  return(df)
}

# lapply to the GO ORA dfs
GOIDBdata<-lapply(GOIDBdata,FUN=GOChangeNames)

pander(GOIDBdata)


#Do the same for the pathway data except don't filter the source name


#lapply to the PW ORA dfs
PwayIDBdata<-shortIDBdata[5:7]

names(GOIDBdata)<-names(IDBdata)[5:7]

PWChangeNames<-function(df){
  names(df)<-c("Pathway Name","Corrected P Value", "Source.Name")
  return(df)
}

PwayIDBdata <-lapply(shortIDBdata[5:7],FUN=PWChangeNames)

PwayIDBdata<-lapply(PwayIDBdata, FUN=slice, 1:10)

pander(PwayIDBdata)

```

GO analysis filtered for just the ones that fall in the "Extracellular" cerebralLocalization category

First the "UP" data


```{r,echo=FALSE,message=FALSE, warning=FALSE}
######### READING IN GENE DATA FROM INNATE DB
geneFolder <- "J:/MacLabUsers/HLADIK SHARED/Projects/Herpes study/Herpes-Project-1/INNATE DB RESULTS/geneSpreadsheets/explant"

geneFiles <- list.files(geneFolder, pattern="all")

geneFilesPath<-paste(geneFolder, "/",geneFiles, sep="")


geneIDBdata <- lapply(geneFilesPath, read.delim, sep="\t", header=TRUE)

names(geneIDBdata)<-str_replace(geneFiles,pattern=".txt",replacement="")

#There are a lot of columns in the files and several have lots of entries separated by |

#I will just keep the entrez ID, symbol (called "name")and goTerms


shortgeneIDBdata<-lapply(geneIDBdata, FUN = select, entrez, name,fullname,goTerms)

shortgeneIDBdata<-lapply(shortgeneIDBdata, FUN=filter, goTerms = str_detect(goTerms, pattern = "GO:0005615")==TRUE |str_detect(goTerms, pattern = "GO:0005576")==TRUE)

#annoyingly, there are several rows in the entrez column that have multiple numbers separated by a comma. All correspond to the same gene name (symbol). I want to separate out those rows, melt them so that there is one entrez id per line and then rbind with the rest of the data.

#first separate the two df's in the list so I can deal with them separately:

genesV186.24DOWN <- shortgeneIDBdata[[1]]

genesV186.24UP<-shortgeneIDBdata[[2]]

noCommas<- function(df){
  if(all(str_detect(df$entrez,",")==FALSE)){
    
    rownames(df)<-NULL
    
    m<-df[,c("entrez","name","fullname")]
    
    return(m) ## This part is for the df's in the list that DON'T have any commas and should be left alone
  }
  
  x<-filter(df,str_detect(df$entrez,",")==TRUE)
  
  x$position<-rownames(x)
  
  rownames(x)<-NULL
  
  
  y<-melt(str_split(x$entrez, pattern=","))#if comma, split, then melt
  
  colnames(y)<-c("singleEntrez","position")#position indicates the original position the entrez was in
  
  z<-merge(y, x, by="position")#will get the names and full names to repeat
  
  a<-z[,c("singleEntrez","name","fullname")] #just get the columns I want
  
  names(a)[1]<-"entrez"
  #next step rbinds the fixed data with its corresp data that had no commas and leaves out the goTerms column
  b<-filter(df,str_detect(df$entrez,",")==FALSE)%>%
    select(-goTerms)%>%
    rbind(a)
  
  return(b)

}



ExtracellularGenesV186.24UP<-noCommas(genesV186.24UP)


save(ExtracellularGenesV186.24UP, file="ExtracellularGenesV186.24UP.Rdata")

ExtracellularGenesV186.24DOWN<-noCommas(genesV186.24DOWN)

save(ExtracellularGenesV186.24DOWN, file="ExtracellularGenesV186.24DOWN.Rdata")





```

The  genes that they have in common:

```{r,echo=FALSE,message=FALSE, warning=FALSE}
#which do the V186.24 up and down have in common?
intersect(ExtracellularGenesV186.24DOWN$fullname,ExtracellularGenesV186.24UP$fullname)

```

SessionInfo()

```{r,echo=FALSE,message=FALSE, warning=FALSE}

#trying to get go term names out of biomart instead of IDB. IDB gives the same name and symbol for different (but related) entrez IDs

library(biomaRt)

ensembl<-useMart(host="www.ensembl.org", "ENSEMBL_MART_ENSEMBL", dataset="hsapiens_gene_ensembl")

goids<-getBM(attributes=c("entrezgene","go_id","name_1006"),
             filters = "entrezgene",values=ExtracellularGenesV186.24DOWN$entrez,
             mart = ensembl)

sessionInfo()
